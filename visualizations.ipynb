{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Creating a function f(X) with a slope of -5\n",
    "X = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
    "func = -5 * X\n",
    " \n",
    "# Adding Gaussian noise to the function f(X) and saving it in Y\n",
    "Y = func + 0.4 * torch.randn(X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the function for forward pass for prediction\n",
    "def forward(x):\n",
    "    return w * x + b\n",
    " \n",
    "# evaluating data points with Mean Square Error (MSE)\n",
    "def criterion(y_pred, y):\n",
    "    return torch.mean((y_pred - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w = torch.tensor(-10.0, requires_grad=True)\n",
    "b = torch.tensor(-20.0, requires_grad=True)\n",
    " \n",
    "step_size = 0.1\n",
    "loss_BGD = []\n",
    "n_iter = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 24.8067],\n",
       "        [ 24.3069],\n",
       "        [ 23.8071],\n",
       "        [ 23.3073],\n",
       "        [ 22.8075],\n",
       "        [ 22.3076],\n",
       "        [ 21.8078],\n",
       "        [ 21.3080],\n",
       "        [ 20.8082],\n",
       "        [ 20.3084],\n",
       "        [ 19.8085],\n",
       "        [ 19.3087],\n",
       "        [ 18.8089],\n",
       "        [ 18.3091],\n",
       "        [ 17.8092],\n",
       "        [ 17.3094],\n",
       "        [ 16.8096],\n",
       "        [ 16.3098],\n",
       "        [ 15.8100],\n",
       "        [ 15.3101],\n",
       "        [ 14.8103],\n",
       "        [ 14.3105],\n",
       "        [ 13.8107],\n",
       "        [ 13.3108],\n",
       "        [ 12.8110],\n",
       "        [ 12.3112],\n",
       "        [ 11.8114],\n",
       "        [ 11.3116],\n",
       "        [ 10.8117],\n",
       "        [ 10.3119],\n",
       "        [  9.8121],\n",
       "        [  9.3123],\n",
       "        [  8.8125],\n",
       "        [  8.3126],\n",
       "        [  7.8128],\n",
       "        [  7.3130],\n",
       "        [  6.8132],\n",
       "        [  6.3133],\n",
       "        [  5.8135],\n",
       "        [  5.3137],\n",
       "        [  4.8139],\n",
       "        [  4.3141],\n",
       "        [  3.8142],\n",
       "        [  3.3144],\n",
       "        [  2.8146],\n",
       "        [  2.3148],\n",
       "        [  1.8149],\n",
       "        [  1.3151],\n",
       "        [  0.8153],\n",
       "        [  0.3155],\n",
       "        [ -0.1843],\n",
       "        [ -0.6842],\n",
       "        [ -1.1840],\n",
       "        [ -1.6838],\n",
       "        [ -2.1836],\n",
       "        [ -2.6834],\n",
       "        [ -3.1833],\n",
       "        [ -3.6831],\n",
       "        [ -4.1829],\n",
       "        [ -4.6827],\n",
       "        [ -5.1826],\n",
       "        [ -5.6824],\n",
       "        [ -6.1822],\n",
       "        [ -6.6820],\n",
       "        [ -7.1818],\n",
       "        [ -7.6817],\n",
       "        [ -8.1815],\n",
       "        [ -8.6813],\n",
       "        [ -9.1811],\n",
       "        [ -9.6810],\n",
       "        [-10.1808],\n",
       "        [-10.6806],\n",
       "        [-11.1804],\n",
       "        [-11.6802],\n",
       "        [-12.1801],\n",
       "        [-12.6799],\n",
       "        [-13.1797],\n",
       "        [-13.6795],\n",
       "        [-14.1793],\n",
       "        [-14.6792],\n",
       "        [-15.1790],\n",
       "        [-15.6788],\n",
       "        [-16.1786],\n",
       "        [-16.6785],\n",
       "        [-17.1783],\n",
       "        [-17.6781],\n",
       "        [-18.1779],\n",
       "        [-18.6777],\n",
       "        [-19.1776],\n",
       "        [-19.6774],\n",
       "        [-20.1772],\n",
       "        [-20.6770],\n",
       "        [-21.1768],\n",
       "        [-21.6767],\n",
       "        [-22.1765],\n",
       "        [-22.6763],\n",
       "        [-23.1761],\n",
       "        [-23.6760],\n",
       "        [-24.1758],\n",
       "        [-24.6756]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = forward(X)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, \t600.7799072265625, \t-1.8573989868164062, \t-16.040536880493164\n",
      "1, \t346.0668640136719, \t-7.248918056488037, \t-12.791540145874023\n",
      "2, \t204.41571044921875, \t-3.6202847957611084, \t-10.246257781982422\n",
      "3, \t123.262939453125, \t-6.015130996704102, \t-8.173745155334473\n",
      "4, \t75.55224609375, \t-4.397043228149414, \t-6.5396833419799805\n",
      "5, \t46.897098541259766, \t-5.459967136383057, \t-5.216253280639648\n",
      "6, \t29.3934383392334, \t-4.737762928009033, \t-4.16813850402832\n",
      "7, \t18.562408447265625, \t-5.208992004394531, \t-3.3224244117736816\n",
      "8, \t11.79544448852539, \t-4.886224746704102, \t-2.6505656242370605\n",
      "9, \t7.537757396697998, \t-5.094791889190674, \t-2.1098508834838867\n",
      "10, \t4.845252513885498, \t-4.950270652770996, \t-1.6793646812438965\n",
      "11, \t3.136390447616577, \t-5.042361259460449, \t-1.3335305452346802\n",
      "12, \t2.0490424633026123, \t-4.977478504180908, \t-1.057784080505371\n",
      "13, \t1.3559194803237915, \t-5.017998218536377, \t-0.8365381360054016\n",
      "14, \t0.9135347604751587, \t-4.9887590408325195, \t-0.6599465012550354\n",
      "15, \t0.6309332847595215, \t-5.006495475769043, \t-0.518380880355835\n",
      "16, \t0.45029327273368835, \t-4.993249893188477, \t-0.4053056836128235\n",
      "17, \t0.3347773253917694, \t-5.000953674316406, \t-0.3147130608558655\n",
      "18, \t0.2608850598335266, \t-4.994909286499023, \t-0.24231605231761932\n",
      "19, \t0.21360839903354645, \t-4.9982171058654785, \t-0.1843380331993103\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range (n_iter):\n",
    "    # making predictions with forward pass\n",
    "    Y_pred = forward(X)\n",
    "    # calculating the loss between original and predicted data points\n",
    "    loss = criterion(Y_pred, Y)\n",
    "    # storing the calculated loss in a list\n",
    "    loss_BGD.append(loss.item())\n",
    "    # backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
    "    loss.backward()\n",
    "    # updateing the parameters after each iteration\n",
    "    w.data = w.data - step_size * w.grad.data\n",
    "    b.data = b.data - step_size * b.grad.data\n",
    "    # zeroing gradients after each iteration\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "    # priting the values for understanding\n",
    "    print('{}, \\t{}, \\t{}, \\t{}'.format(i, loss.item(), w.item(), b.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[0;32m      2\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      3\u001b[0m loss_fn(model(\u001b[39minput\u001b[39m), target)\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "optimizer.zero_grad()\n",
    "loss_fn(model(input), target).backward()\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
